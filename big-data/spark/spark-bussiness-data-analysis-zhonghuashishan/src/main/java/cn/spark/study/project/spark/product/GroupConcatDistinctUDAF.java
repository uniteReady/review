package cn.spark.study.project.spark.product;

import org.apache.spark.sql.Row;
import org.apache.spark.sql.expressions.MutableAggregationBuffer;
import org.apache.spark.sql.expressions.UserDefinedAggregateFunction;
import org.apache.spark.sql.types.DataType;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructType;

import java.util.Arrays;

public class GroupConcatDistinctUDAF extends UserDefinedAggregateFunction {

    //指定输入数据的字段和类型
    private StructType inputSchema = DataTypes.createStructType(
            Arrays.asList(
                    DataTypes.createStructField("cityInfo",DataTypes.StringType,true)
            ));

    //指定缓冲数据的字段和类型
    private StructType bufferSchema = DataTypes.createStructType(
            Arrays.asList(
                    DataTypes.createStructField("bufferCityInfo",DataTypes.StringType,true)
            ));

    //指定返回类型
    private DataType dataType = DataTypes.StringType;

    //指定是否是确定性的
    private boolean deterministic=true;


    @Override
    public StructType inputSchema() {
        return inputSchema;
    }

    @Override
    public StructType bufferSchema() {
        return bufferSchema;
    }

    @Override
    public DataType dataType() {
        return dataType;
    }

    @Override
    public boolean deterministic() {
        return deterministic;
    }

    /**
     * 初始化
     * 可以认为是，你自己在内部指定一个初始的值
     * @param buffer
     */
    @Override
    public void initialize(MutableAggregationBuffer buffer) {
        buffer.update(0,"");
    }

    /**
     * 更新
     * 可以认为是，一个一个的将组内的字段值传递进来，实现拼接的逻辑
     * @param buffer
     * @param input
     */
    @Override
    public void update(MutableAggregationBuffer buffer, Row input) {
        //获取缓冲中的已经拼接过的城市信息串
        String bufferCityInfo = buffer.getString(0);
        //获取本次输入的待拼接的城市信息
        String cityInfo = input.getString(0);
        //在这里要实现去重的逻辑
        //判断：之前没有拼接过的某个城市信息，那么这里才可以拼接进去
        if(! bufferCityInfo.contains(cityInfo)){
            //第一次拼接 bufferCityInfo还是初始化的值 直接拼接
            if("".equals(bufferCityInfo)){
                bufferCityInfo += cityInfo;
            }else {
                bufferCityInfo += ","+cityInfo;
            }

        }
        buffer.update(0,bufferCityInfo);
    }

    /**
     * 合并
     * update操作，可能是针对一个分组内的部分数据，在某个节点上发生的
     * 但是可能一个分组内的数据，会分部在多个节点上处理
     * 此时就要用merge操作，将各个环节上分布式拼接好的串，合并起来
     * @param buffer1
     * @param buffer2
     */
    @Override
    public void merge(MutableAggregationBuffer buffer1, Row buffer2) {
        String bufferCityInfo1 = buffer1.getString(0);
        String bufferCityInfo2 = buffer2.getString(0);
        String[] splits = bufferCityInfo2.split(",");
        for (String cityInfo : splits) {
            if(!bufferCityInfo1.contains(cityInfo)){
                if("".equals(bufferCityInfo1)){
                    bufferCityInfo1 += cityInfo;
                }else {
                    bufferCityInfo1 += ","+ cityInfo;
                }
            }
        }
        buffer1.update(0,bufferCityInfo1);

    }

    /**
     * 计算出最终的结果
     * @param row
     * @return
     */
    @Override
    public Object evaluate(Row row) {
        return row.getString(0);
    }
}
